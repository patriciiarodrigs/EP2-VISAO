{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# @title\n",
    "### EP2 MAC0417 / MAC5768\n",
    "##################################################################\n",
    "# AO PREENCHER ESSE CABEÇALHO COM O MEU NOME E O MEU NÚMERO USP,#\n",
    "# DECLARO QUE SOU O ÚNICO AUTOR E RESPONSÁVEL PELA RESOLUÇÃO #\n",
    "# DESTE EP. #\n",
    "# TODAS AS PARTES FORAM DESENVOLVIDAS E IMPLEMENTADAS POR MIM, #\n",
    "# SEGUINDO AS INSTRUÇÕES E QUE PORTANTO, NÃO CONSTITUEM #\n",
    "# DESONESTIDADE ACADÊMICA OU PLÁGIO. #\n",
    "# #\n",
    "# DECLARO TAMBÉM, QUE SOU RESPONSÁVEL POR TODAS AS CÓPIAS #\n",
    "# DESSE PROGRAMA, E QUE EU NÃO DISTRIBUI OU FACILITEI A #\n",
    "# SUA DISTRIBUIÇÃO. ESTOU CIENTE QUE OS CASOS DE PLÁGIO E #\n",
    "# DESONESTIDADE ACADÊMICA SERÃO TRATADOS SEGUNDO OS CRITÉRIOS #\n",
    "# DEFINIDOS NO CÓDIGO DE ÉTICA DA USP. #\n",
    "# #\n",
    "# ENTENDO QUE JUPYTER NOTEBOOKS SEM ASSINATURA NÃO SERÃO #\n",
    "# CORRIGIDOS E, AINDA ASSIM, PODERÃO SER PUNIDOS POR #\n",
    "# DESONESTIDADE ACADÊMICA. #\n",
    "# #\n",
    "# #\n",
    "# Nome : Patrícia da Silva Rodrigues #\n",
    "# NUSP : 11315590 #\n",
    "# Turma: MAC0417 #\n",
    "# Prof.: Ronaldo Fumio Hashimoto #\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread, imsave\n",
    "import cv2\n",
    "import csv \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gerando metadados do banco de imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"Metadados\"):\n",
    "    os.makedirs(\"Metadados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funcoes auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para separar nomes dos objetos\n",
    "def separar_nomes(caminho_imagem):\n",
    "    nome_arquivo = caminho_imagem.split('/')[-1]\n",
    "    nome_arquivo_sem_extensao = nome_arquivo.split('.')[0]\n",
    "    palavras = nome_arquivo_sem_extensao.split('_')\n",
    "    return palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para obter dados da imagem a partir do diretório\n",
    "def dados_imagem(diretorio):\n",
    "    partes = diretorio.split('/')\n",
    "    partes.pop(0)\n",
    "    partes.pop(-1)\n",
    "    return partes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gerando metadados do banco original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processar_imagens(diretorio_raiz):\n",
    "    metadados_lista = []\n",
    "    csv_filename = 'Metadados/metadados.csv'  # Define CSV filename here\n",
    "\n",
    "    for root, dirs, files in os.walk(diretorio_raiz):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpeg\") or file.endswith(\".jpg\"):\n",
    "                caminho_imagem = os.path.join(root, file)\n",
    "                dados = dados_imagem(caminho_imagem)  # Assuming dados_imagem is defined elsewhere\n",
    "                objetos = separar_nomes(caminho_imagem)  # Assuming separar_nomes is defined elsewhere\n",
    "                \n",
    "                metadados_lista.append({\n",
    "                    \"nome_imagem\": file,\n",
    "                    # \"caminho_imagem\": caminho_imagem,\n",
    "                    \"objetos\": \",\".join(objetos),\n",
    "                    \"fundo\": dados[0] if len(dados) > 0 else \"\",\n",
    "                    \"iluminacao\": dados[1] if len(dados) > 1 else \"\",\n",
    "                })\n",
    "\n",
    "    os.makedirs(os.path.dirname(csv_filename), exist_ok=True)\n",
    "\n",
    "    fieldnames = ['nome_imagem', 'objetos','fundo', 'iluminacao']\n",
    "\n",
    "    with open(csv_filename, mode='w', newline='') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for metadados in metadados_lista:\n",
    "            writer.writerow(metadados)\n",
    "\n",
    "    print(f\"Dados escritos no arquivo {csv_filename}!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processar_imagens('banco_de_imagens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicando a escala em niveis de cinza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funcao para transformar uma imagem em niveis de cinza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constantes para a conversao em escala de cinza\n",
    "RGB_TO_GRAY = [0.2989, 0.5870, 0.1140]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao que converte RGB image para grayscale\n",
    "def rgb2gray(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construindo o dataset com as imagens em niveis de cinza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = 'Metadados/metadados.csv'\n",
    "metadata = pd.read_csv(csv_path)\n",
    "\n",
    "\n",
    "\n",
    "base_dir = 'banco_de_imagens'\n",
    "new_base_dir = 'originalGrayDataset'\n",
    "\n",
    "\n",
    "for index, row in metadata.iterrows():\n",
    "    try:\n",
    "        image_name = row['nome_imagem']\n",
    "        image_path = os.path.join(base_dir, row['fundo'], row['iluminacao'], image_name)\n",
    "        \n",
    "        if os.path.exists(image_path):\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            if image is not None:\n",
    "                image = cv2.resize(image, (0, 0), fx=0.5, fy=0.5)\n",
    "                gray_image = rgb2gray(image)\n",
    "                new_image_dir = os.path.join(new_base_dir, row['fundo'], row['iluminacao'])\n",
    "                os.makedirs(new_image_dir, exist_ok=True)\n",
    "                new_image_path = os.path.join(new_image_dir, image_name)\n",
    "                gray_image_uint8 = (gray_image * 255).astype('uint8')  \n",
    "                cv2.imwrite(new_image_path, gray_image_uint8)\n",
    "    except KeyError as e:\n",
    "        print(f\"KeyError: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Associando as imagens em niveis de cinza ao arquivo de metadados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Função para processar as imagens e extrair metadados\n",
    "def processar_imagens(diretorio_raiz):\n",
    "    diretorio_metadados = \"Metadados_Gray_Image\"\n",
    "    if not os.path.exists(diretorio_metadados):\n",
    "        os.makedirs(diretorio_metadados)\n",
    "\n",
    "    metadados_lista = []\n",
    "    for root, dirs, files in os.walk(diretorio_raiz):\n",
    "        for file in files:\n",
    "            if file.endswith(\".jpeg\") or file.endswith(\".jpg\"):\n",
    "                caminho_imagem = os.path.join(root, file)\n",
    "                dados = dados_imagem(caminho_imagem)\n",
    "                objetos = separar_nomes(caminho_imagem)\n",
    "\n",
    "                \n",
    "                metadados_lista.append({\n",
    "                    \"nome_imagem\": file,\n",
    "                    # \"caminho_imagem\": caminho_imagem,\n",
    "                    \"objetos\": \",\".join(objetos),\n",
    "                    \"fundo\": dados[0] if len(dados) > 0 else \"\",\n",
    "                    \"iluminacao\": dados[1] if len(dados) > 1 else \"\"\n",
    "                })\n",
    "    # Salva os metadados em um CSV\n",
    "    metadados_df = pd.DataFrame(metadados_lista)\n",
    "    if not metadados_df.empty:\n",
    "        metadados_df.to_csv(\"Metadados_gray_image/metadados_gray_image.csv\", index=False)\n",
    "    else:\n",
    "        print(\"Nenhum metadado foi extraído das imagens.\")\n",
    "\n",
    "    print(f\"Dados escritos no arquivo {diretorio_metadados}!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processar todas as imagens nos subdiretórios\n",
    "processar_imagens(\"originalGrayDataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EP2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1 - Data Augmentation (Function Image Tranformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funcao que inverte kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverte(matriz):\n",
    "    matriz_revertida = []\n",
    "    for linha in reversed(matriz):\n",
    "        matriz_revertida.append(list(reversed(linha)))\n",
    "    matriz_revertida = np.array(matriz_revertida)\n",
    "    return matriz_revertida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "funcao que aplica o kernel na imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_kernel(image, kernel):\n",
    "    height, width = image.shape\n",
    "    k_height, k_width = kernel.shape\n",
    "    output = np.zeros((height, width))\n",
    "\n",
    "    pad_height = k_height // 2\n",
    "    pad_width = k_width // 2\n",
    "\n",
    "    padded_image = np.pad(image, ((pad_height, pad_height), (pad_width, pad_width)), mode='constant')\n",
    "    \n",
    "    output = np.zeros_like(image)\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            output[i, j] = np.sum(kernel * padded_image[i:i+k_height, j:j+k_width])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "contrast stretching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_stretching(image):\n",
    "    if image is None:\n",
    "        return None\n",
    "    \n",
    "    a, b = np.min(image), np.max(image)\n",
    "    if a == b:\n",
    "        return image\n",
    "    \n",
    "    stretched_image = (image - a) * (255 / (b - a))\n",
    "    stretched_image = np.clip(stretched_image, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    return stretched_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(image, c):\n",
    "    return c * np.log1p(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exp transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_transform(image, c, gamma):\n",
    "    return c * np.power(image, gamma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "laplacian filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplacian_filter(image):\n",
    "    # kernel Laplaciano\n",
    "    laplacian_kernel = np.array([[0, 1, 0],\n",
    "                                 [1, -4, 1],\n",
    "                                 [0, 1, 0]])\n",
    "    \n",
    "    # Aplicando a correlação na imagem usando o kernel Laplaciano\n",
    "    laplacian_image = apply_kernel(image, laplacian_kernel)\n",
    "    \n",
    "    return laplacian_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mean filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_filter(image):\n",
    "    mean_kernel = np.ones((3, 3)) / 9\n",
    "    mean_kernel = reverte( mean_kernel) #invertendo o kernel para a convolucao\n",
    "    mean_image = apply_kernel(image, mean_kernel) # aplicando\n",
    "\n",
    "    return mean_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aplicando a transformacao "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = {\n",
    "    'contrast_stretching': contrast_stretching,\n",
    "    'log_transform': lambda image, c=2: log_transform(image, c),  # aqui podemos definir o valor das constantes \n",
    "    'exp_transform': lambda image, c=2, gamma=3: exp_transform(image, c, gamma), # aqui podemos definir o valor das constantes \n",
    "    'laplacian_filter': laplacian_filter,\n",
    "    'mean_filter': mean_filter,\n",
    "}\n",
    "\n",
    "\n",
    "metadados_augmentedDataset_image = []\n",
    "base_dir = 'originalGrayDataset'\n",
    "csv_path = 'Metadados_gray_image/metadados_gray_image.csv'\n",
    "new_base_dir = 'augmentedDataset'\n",
    "\n",
    "metadata = pd.read_csv(csv_path)\n",
    "\n",
    "if not os.path.exists(new_base_dir):\n",
    "    os.makedirs(new_base_dir)\n",
    "\n",
    "for index, row in metadata.iterrows():\n",
    "    caminho_imagem = os.path.join(base_dir, row['fundo'], row['iluminacao'], row['nome_imagem'])\n",
    "    grayscale_image = cv2.imread(caminho_imagem, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    if grayscale_image is None:\n",
    "        print(f\"Erro: Não foi possível ler a imagem {caminho_imagem}\")\n",
    "        continue\n",
    "\n",
    "    for transformation_name, transformation_func in transformations.items():\n",
    "        output_dir = os.path.join(new_base_dir, transformation_name, row['fundo'], row['iluminacao'])\n",
    "\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "\n",
    "        transformed_image = transformation_func(grayscale_image)\n",
    "\n",
    "        if transformed_image is None:\n",
    "            print(f\"Erro na transformação {transformation_name} para a imagem {caminho_imagem}\")\n",
    "            continue\n",
    "            \n",
    "        output_image_path = os.path.join(output_dir, row['nome_imagem'])\n",
    "        cv2.imwrite(output_image_path, transformed_image)\n",
    "\n",
    "        # Registro dos metadados no DataFrame\n",
    "        metadados_augmentedDataset_image.append({\n",
    "            'nome_imagem': row['nome_imagem'],\n",
    "            'iluminacao': row['iluminacao'],\n",
    "            'fundo': row['fundo'],\n",
    "            'filtro': transformation_name\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gera os metadados da nova base de dados (augmentedDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csv_filename = 'Metadados_Augmented_Data/metadados_augmented.csv'\n",
    "os.makedirs(os.path.dirname(csv_filename), exist_ok=True)\n",
    "\n",
    "fieldnames = ['nome_imagem', 'fundo', 'iluminacao', 'filtro']\n",
    "\n",
    "with open(csv_filename, mode='w', newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for metadados in metadados_augmentedDataset_image:\n",
    "        writer.writerow(metadados)\n",
    "\n",
    "print(f\"Dados escritos no arquivo {csv_filename}!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
